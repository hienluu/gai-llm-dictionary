## GAI & LLMs Dictionary

One of the challenges when learning new technology or a field of study is understanding their commonly used terminologies and acronyms.  This repository aims to help those who are new to GAI and LLMs by providing a clear and concise definition of each of the commonly used terminologies and acronyms in these areas.  Each term in the dictionary is accompanied by a definition and a link to a relevant resource.

My hope is this GAI & LLMs Dictionary will become a valuable resource for anyone who is interested in learning about and keeping up with the rapidly evolding GAI and LLMs

Public contributions are very much welcome


| Term/Acronym        | Definition           | Resource  |
| ------------------- |:--------------------:| ---------:|
| GAI                 | A type of AI that can create new content, such as text, images, videos, etc. An example of GAI is ChatGPT, Bard, Bing Chat,etc| |
| LLMs                | Large language models are a type of AI that are trained on massive datasets of text, code, books, and more. They are able capable of many NLP related tasks, such as generate text, translate languages, summarize text, extract meaning and intent, etc.| |
| GPT                 | Generated pre-trained transformer, which are ML models that are trained to understand natural language and code.  They provide text outputs in response to their input| [GPT models](https://platform.openai.com/docs/guides/gpt)|
| Prompts             | The inputs to GPTs | |
| Tokens              | LLMs read and write text in chunks called tokens, which are common sequences of characters found in text.  LLMs understand the statistical relationships between tokens and excel at producing the next token in a sequence of tokens.  One token generally corresponds to ~4 characters of text for common English text, which translates to roughly 3/4 of a word.  This means 100 tokens is roughly equivalent to 75 words | [OpenAI tokenizer] (https://platform.openai.com/tokenizer)|
